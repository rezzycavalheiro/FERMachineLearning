{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMImPgvz/yO1xgW58yQnFjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezzycavalheiro/FERMachineLearning/blob/master/TCC1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL84rOsApbGk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goumAHJcnB28",
        "colab_type": "text"
      },
      "source": [
        "This code is a prototype for my final course project. \n",
        "\n",
        "**Course**: Computer Science  \n",
        "**University**: Pontifical Catholic University of ParanÃ¡ (PUC PR)  \n",
        "**Student's name**: Renata Cavalheiro da Silva  \n",
        "    \n",
        "**Project's title**: Classification of Facial Expressions Using Deep Learning\n",
        "\n",
        "> **Description**: This project aims to build a Facial Expresion Recognition (FER) algorithm that presents a high accuracy and that could be adapted for psychologists and psychiatrists to use during their appointments with their pacients. The idea is that this tool would help the medical professionals to record and evaluate the expressions presented by their pacients, and use the data to check if they match what the pacient is saying. This is due to people being able to say something when they are feeling another - like someone with depressive symptoms saying they don't feel sadness, but in their expression actually showing this emotion. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7TQUa6Hr9Ch",
        "colab_type": "code",
        "outputId": "0da7d7fc-0c7c-417f-e611-b61b984b1335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# ACCESSING THE FOLDER ON MY DRIVE AND GETTING ITS CONTENT\n",
        "\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print(\"Auth Success\")\n",
        "\n",
        "# Getting the id of the folder which contains the files \n",
        "folder_id = '1vtV4IahA5vu3P8WQRRTPgRK8qPr1umKH'\n",
        "lister = drive.ListFile({'q': \"'%s' in parents\" % folder_id}).GetList()\n",
        "\n",
        "for item in lister:\n",
        "    print(item['title']) \n",
        "    print('title: %s, mimeType: %s' % (item['title'], item['mimeType']))\n",
        "    mimetypes = {\n",
        "        # Drive Document files as PDF\n",
        "        'application/vnd.google-apps.document': 'application/pdf',\n",
        "\n",
        "        # Drive Sheets files as MS Excel files.\n",
        "        'application/vnd.google-apps.spreadsheet': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
        "    }\n",
        "    download_mimetype = None\n",
        "    if item['mimeType'] in mimetypes:\n",
        "        download_mimetype = mimetypes[file['mimeType']]\n",
        "        item.GetContentFile(file['title'], mimetype=download_mimetype)\n",
        "\n",
        "        item.GetContentFile(r'C:\\Users\\Renata\\Desktop\\googedrive\\\\' + item['title'], mimetype=download_mimetype)\n",
        "    else: \n",
        "        item.GetContentFile(r'C:\\Users\\Renata\\Desktop\\googedrive\\\\' + item['title'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auth Success\n",
            "fer2013.csv\n",
            "title: fer2013.csv, mimeType: text/csv\n",
            "README\n",
            "title: README, mimeType: application/octet-stream\n",
            "fer2013.bib\n",
            "title: fer2013.bib, mimeType: text/x-bibtex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-TelYm2gqL7",
        "colab_type": "code",
        "outputId": "4ef904ba-3edb-4dc9-b285-6b0f50428cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "# READING THE FILE\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Labeling the file with the characteristics\n",
        "\n",
        "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "names=['emotion','pixels','usage']\n",
        "filename = r'C:\\Users\\Renata\\Desktop\\googedrive\\\\fer2013.csv'\n",
        "fer2013 = pd.read_csv(r'C:\\Users\\Renata\\Desktop\\googedrive\\\\fer2013.csv', names=names, na_filter=False)\n",
        "print(fer2013.info())\n",
        "im = fer2013['pixels']\n",
        "fer2013.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35888 entries, 0 to 35887\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  35888 non-null  object\n",
            " 1   pixels   35888 non-null  object\n",
            " 2   usage    35888 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 841.2+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>emotion</td>\n",
              "      <td>pixels</td>\n",
              "      <td>Usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     usage\n",
              "0  emotion                                             pixels     Usage\n",
              "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
              "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
              "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
              "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
              "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVeuDIEiv5w4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b57b3558-c5e0-415f-a72a-35f300b82741"
      },
      "source": [
        "# GETTING THE DATA AND CHECKING THE SIZE OF THE SET\n",
        "\n",
        "def getData(filename):\n",
        "    # images are 48x48\n",
        "    # N = 35887\n",
        "    Y = []\n",
        "    X = []\n",
        "    first = True\n",
        "    for line in open(filename):\n",
        "        if first:\n",
        "            first = False\n",
        "        else:\n",
        "            row = line.split(',')\n",
        "            Y.append(int(row[0]))\n",
        "            X.append([int(p) for p in row[1].split()])\n",
        "\n",
        "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "X, Y = getData(filename)\n",
        "num_class = len(set(Y))\n",
        "print(num_class)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U490syHRxUC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras with tensorflow backend\n",
        "N, D = X.shape\n",
        "X = X.reshape(N, 48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MEetsGFv5pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
        "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
        "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDbmVEZayglK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import *\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx9pqou0ypY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "b2ef307c-342d-4e55-f3bc-d9d8278b71f4"
      },
      "source": [
        "def my_model():\n",
        "    model = Sequential()\n",
        "    input_shape = (48,48,1)\n",
        "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
        "    # model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(7))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
        "    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n",
        "    #model.summary()\n",
        "    \n",
        "    return model\n",
        "model=my_model()\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 48, 48, 64)        1664      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 48, 48, 64)        102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 128)       409728    \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               2359424   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 903       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 3,490,119\n",
            "Trainable params: 3,489,479\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLNo1akgysCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "3e7bea0c-4350-4fa7-a742-4220c5f7b122"
      },
      "source": [
        "path_model='model_filter.h5' # save model at this location after each epoch\n",
        "K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
        "model=my_model() # create the model\n",
        "K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
        "# fit the model\n",
        "h=model.fit(x=X_train,     \n",
        "            y=y_train, \n",
        "            batch_size=64, \n",
        "            epochs=10, \n",
        "            verbose=1, \n",
        "            validation_data=(X_test,y_test),\n",
        "            shuffle=True,\n",
        "            callbacks=[\n",
        "                ModelCheckpoint(filepath=path_model),\n",
        "            ]\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32298 samples, validate on 3589 samples\n",
            "Epoch 1/10\n",
            "32298/32298 [==============================] - 2996s 93ms/step - loss: 1.6957 - accuracy: 0.3384 - val_loss: 1.4725 - val_accuracy: 0.4425\n",
            "Epoch 2/10\n",
            "32298/32298 [==============================] - 2968s 92ms/step - loss: 1.3583 - accuracy: 0.4777 - val_loss: 1.2675 - val_accuracy: 0.5132\n",
            "Epoch 3/10\n",
            "32298/32298 [==============================] - 2991s 93ms/step - loss: 1.1675 - accuracy: 0.5581 - val_loss: 1.2608 - val_accuracy: 0.5216\n",
            "Epoch 4/10\n",
            "  832/32298 [..............................] - ETA: 45:53 - loss: 1.0149 - accuracy: 0.6298"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}